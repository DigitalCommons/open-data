#!/usr/bin/env ruby
# coding: utf-8
#
# This script controls a pipeline of processes that convert the original
# CSV data into the se_open_data standard, one step at a time.
#
# We aim to put only logic specific to this project in this file, and
# keep it brief and clear. Shared logic should go into the {SeOpenData}
# library.
#
# This script can be invoked directly, or as part of the {SeOpenData}
# library's command-line API {SeOpenData::Cli}. For example, this
# just runs the conversion step (or specifically: a script in the
# current directory called `converter`):
#
#     seod convert 
#
# And this runs the complete chain of commands generating and
# deploying the linked data for this project, as configured by
# `settings/config.txt`:
#
#     seod run-all
#
# See the documentation on [`seod`]({SeOpenData::Cli}) for more
# information.

require_relative '../tools/se_open_data/lib/load_path'
require 'se_open_data'
require 'se_open_data/config'
require 'se_open_data/csv/add_postcode_lat_long'
require 'se_open_data/csv/schema'
require 'se_open_data/csv/schema/types'
require 'csv'

# Code related to the DotCoop SSE initiative data
module DotCoop

  
  # This defines the input CSV schema we expect (after clean-up an index generation)
  Schema = SeOpenData::CSV::Schema.new(
    id: :dotCoop,
    name: "DotCoop",
    version: 20200810, 
    comment: 'Initial version, may require amendment',
    primary_key: [:registrant_id],
    fields: [
      {id: :domain,
       header: 'Domain',
       desc: '',
       comment: '',
      },
      {id: :registrant_id,
       header: 'RegistrantId',
       desc: 'A unique identifier for the registrant',
       comment: '',
      },
      {id: :creation_date,
       header: 'CreationDate',
       desc: '',
       comment: '',
      },
      {id: :organisation,
       header: 'Organisation',
       desc: '',
       comment: '',
      },
      {id: :street_number,
       header: 'StreetNumber',
       desc: '',
       comment: '',
      },
      {id: :street_name,
       header: 'StreetName',
       desc: '',
       comment: '',
      },
      {id: :street_address,
       header: 'StreetAddress',
       desc: '',
       comment: '',
      },
      {id: :city,
       header: 'City',
       desc: '',
       comment: '',
      },
      {id: :state,
       header: 'State',
       desc: '',
       comment: '',
      },
      {id: :country,
       header: 'Country',
       desc: '',
       comment: '',
      },
      {id: :post_code,
       header: 'PostCode',
       desc: '',
       comment: '',
      },
      {id: :last_changed,
       header: 'LastChanged',
       desc: '',
       comment: '',
      },
    ]
  )

  PostcodeIndexSchema = SeOpenData::CSV::Schema.new(
    id: :postcode_index,
    name: "Registrant postcode index",
    version: 20200810, 
    comment: 'Initial version, may require amendment',

    fields: [
      {id: :uri,
       header: 'URI',
       desc: "The registrant's linked-data URI identifying it",
       comment: '',
      },
      {id: :name,
       header: 'Name',
       desc: "The registrant's name",
       comment: '',
      },
      {id: :postcode,
       header: 'Postcode',
       desc: "The registrant's postcode",
       comment: '',
      },
    ]
  )

  # The output schema
  StdSchema = SeOpenData::CSV::Schemas::Versions[1]
  
  # A convenient alias...
  types = SeOpenData::CSV::Schema::Types
  
  # This defines the schema mapping for dotCoop data into the
  # standard schema.
  #
  # The logic that maps the input field data is defined in the
  # do-block. It will be wrapped in a loop which reads the input file
  # and writes the output file. See the documentation for
  # {SeOpenData::CSV::Schema.converter}.
  #
  # The response data downloaded from limesurvey via the API appears
  # to be different to that downloaded previously.
  # - semi-colon delimited, not comma delimited
  # - 'activities' field contains a identifier, not a human-readable phrase.
  #
  # The delimiter appears to be configurable in the web download, but not in the API.
  # https://bugs.limesurvey.org/view.php?id=13747
  Converter = SeOpenData::CSV::Schema.converter(
    from_schema: Schema,
    to_schema: StdSchema,
    input_csv_opts: {skip_blanks: true}
#    output_csv_opts: {quote_empty: false}
  ) do | # These parameters match source schema field ids
         domain:,
         registrant_id:,
         creation_date:,
         organisation:,
         street_number:,
         street_name:,
         street_address:,
         city:,
         state:,
         country:,
         post_code:,
         last_changed:
         |
         # A mapping to the target schema field ids
         {
           id: registrant_id.sub('C','').sub('-CNIC',''),
           name: organisation ? organisation : "No Name",
           description: '',
           organisational_structure: '',
           primary_activity: '',
           activities: '',
           street_address: street_address,
           locality: city,
           region: state,
           postcode: post_code,
           country_name: types.country_code_to_name(country),
           homepage: "http://#{domain}",
           phone: '',
           email: '',
           twitter: '',
           facebook: '',
           companies_house_number: '',
           qualifiers: '',
           latitude: '',
           longitude: '',
           geocontainer: '',
           geocontainer_lat: '',
           geocontainer_lon: '',
         }
  end
         
  # Entry point if invoked as a script.
  #
  # See {SeOpenData::Config} for information about this file. It
  # defines the locations of various resources, and sets options on
  # the conversion process.
  def self.main
    # Find the config file...
    config = SeOpenData::Config.load

    # original src csv file
    original_csv = File.join(config.SRC_CSV_DIR, config.ORIGINAL_CSV)

    # Intermediate csv files
    outlets_csv = File.join(config.GEN_CSV_DIR, "outlets.csv")
    deduplicated_csv = File.join(config.GEN_CSV_DIR, "de-duplicated.csv")
    ignored_duplicates_csv = File.join(config.GEN_CSV_DIR, "ignored-duplicates.csv")
    corrected_geo_data_csv = File.join(config.GEN_CSV_DIR, "corrected-geo-data.csv")
    dedup_after_geo_csv = File.join(config.GEN_CSV_DIR, "de-duplicated-after-geo.csv")
    
    # Output csv files
    output_csv = config.STANDARD_CSV
    uri_name_postcode_csv = File.join(config.GEN_CSV_DIR, "uri-name-postcode.csv")

    # Cache files
    geodata_cache = File.join(__dir__, "..", "geodata_cache.json")
    postcode_cache = File.join(__dir__, "..", "postcode_lat_lng.json")
    
    # Get the Geoapify API key
    pass = SeOpenData::Utils::PasswordStore.new(use_env_vars: config.USE_ENV_PASSWORDS)
    api_key = pass.get config.GEOCODER_API_KEY_PATH

    # Transforms the rows from Co-ops UK schema to our standard
    # Note the BOM and encoding flags, which avoid a MalformedCSVError
    Converter.convert File.open(original_csv, "r:bom|utf-8"), outlets_csv
    merge_doms_remove_dups(infile: outlets_csv,
                           outfile: deduplicated_csv,
                           errfile: ignored_duplicates_csv)
    add_postcode_lat_long(infile: deduplicated_csv,
                          outfile: corrected_geo_data_csv,
                          api_key: api_key,
                          lat_lng_cache: config.POSTCODE_LAT_LNG_CACHE,
                          postcode_global_cache: geodata_cache,
                          replace_address: "force")
    merge_doms_remove_dups(infile: corrected_geo_data_csv,
                           outfile: dedup_after_geo_csv,
                           errfile: ignored_duplicates_csv,
                           original_csv: deduplicated_csv)
    merge_doms_dedup_lonlat(infile: dedup_after_geo_csv, outfile: output_csv) 

    make_uri_name_postcode(infile: output_csv, outfile: uri_name_postcode_csv,
                           uri_prefix: config.GRAPH_NAME)
    document_geocoder(converted: deduplicated_csv, postcode_global_cache: geodata_cache,
                      api_key: api_key)

  rescue => e
    raise "error transforming #{original_csv} into #{output_csv}: #{e.message}"
  end

  private

  # FIXME Perhaps move this wrapper somewhere shared?
  def self.add_postcode_lat_long(infile:, outfile:,
                                 api_key:, lat_lng_cache:, postcode_global_cache:,
                                 replace_address: false, csv_opts: {})
    input = File.open(infile, "r:bom|utf-8")
    output = File.open(outfile, "w")
    geocoder = SeOpenData::CSV::Standard::GeoapifyStandard::Geocoder.new(api_key)
    geocoder_headers = SeOpenData::CSV::Standard::GeoapifyStandard::Headers
    subhash = lambda do |hash, *keys|
      keys = keys.select { |k| hash.key?(k) }
      Hash[keys.zip(hash.values_at(*keys))]
    end
    headers = StdSchema.to_h
    SeOpenData::CSV.add_postcode_lat_long(
        input,
        output,
        StdSchema.field(:postcode).header,
        StdSchema.field(:country_name).header,
        subhash.call(headers,
                :geocontainer,
                :geocontainer_lat,
                :geocontainer_lon),
        lat_lng_cache,
        csv_opts,
        postcode_global_cache,
        subhash.call(headers,
                :street_address,
                :locality,
                :region,
                :postcode,
                :country_name),
        replace_address,
        geocoder_headers,
        geocoder
      )
  ensure
    input.close
    output.close
  end

  def self.merge_doms_remove_dups(infile:, outfile:, errfile: File::NULL, original_csv: nil)
    input = File.open(infile, "r:bom|utf-8")
    output = File.open(outfile, "w")
    errstr = File.open(errfile, "w")

    # primary key of the outgoing schema
    keys = StdSchema.primary_key.map { |id| StdSchema.field(id).header } 

    # These fields of the outgoing schema
    domain_header = StdSchema.field(:homepage).header
    name_header = StdSchema.field(:name).header
    
    SeOpenData::CSV.merge_and_de_duplicate(
      input,
      output,
      errstr,
      keys,
      domain_header,
      name_header,
      original_csv
    )
  ensure
    input.close
    output.close
    errstr.close
  end

  # Merges domains in rows of CSV that contain identical IDs.
  #
  # A duplicate is defined as having the same keys as a previous row.
  # OR if all other fields except the key field and the domain field are equal
  def self.merge_doms_dedup_lonlat(infile:, outfile:)
    input = File.open(infile, "r:bom|utf-8")
    output = File.open(outfile, "w")

    domain_header = StdSchema.field(:homepage).header
    name_header = StdSchema.field(:name).header
    lat = StdSchema.field(:geocontainer_lat).header
    lon = StdSchema.field(:geocontainer_lon).header


    SeOpenData::CSV.merge_and_remove_latlon_dups(
      input,
      output,
      domain_header,
      name_header,
      lat,
      lon
    )
  ensure
    input.close
    output.close
  end

  # Makes an index of registrant postcodes
  #
  # @param uri_prefix [String] The prefix to insert ot the beginning
  # of each identifier, to produce the URI in the output
  def self.make_uri_name_postcode(infile:, outfile:, uri_prefix:)
    input = File.open(infile, "r:iso-8859-1")
    output = File.open(outfile, "w")

    converter = SeOpenData::CSV::Schema.converter(
      from_schema: StdSchema,
      to_schema: PostcodeIndexSchema,
    ) do | # These parameters match source schema field ids
           id:,
           name:,
           postcode:,
           **rest
           |
           # A mapping to the target schema field ids
           {
             uri: File.join(uri_prefix, id), # concats with a '/'
             name: name,
             postcode: postcode.upcase.gsub(/\s+/, ""),
           }
           end
           
    converter.convert input, output
  ensure
    input.close
    output.close
  end

  
  # @param postcode_global_cache CSV file where all the postcodes are
  # kept (note that this will be a json in the future @param converted
  # the file used for geocoding @param docs_folder generated
  # documentation folder
  def self.document_geocoder(converted: nil, docs_folder: 'docs/',
                             postcode_global_cache:, api_key:)
    pass = SeOpenData::Utils::PasswordStore.new(use_env_vars: false)
    geoapify = SeOpenData::CSV::Standard::GeoapifyStandard::Geocoder.new(api_key)
    header = StdSchema.field(:homepage).header
    geoapify.gen_geo_report(postcode_global_cache, 0.05, docs_folder, converted, [header])
  end

  class CsvFilter < SeOpenData::CSV::RowReader
    OutputHeaders = {
      uri: "URI",
      name: "Name",
      postcode_normalized: "Postcode"
    }
    CsvHeaders = {
      id: "Identifier",
      name: "Name",
      postcode: "Postcode"
    }
    def initialize(row, uri_prefix:)
      super(row, CsvHeaders)
      @uri_prefix = uri_prefix
    end
    def uri
      @uri_prefix + id
    end
  end

end

# Run the entry point if we're invoked as a script
# This just does the csv conversion.
DotCoop.main if __FILE__ == $0


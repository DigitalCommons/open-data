#!/usr/bin/env ruby
# coding: utf-8
#
# This script controls a pipeline of processes that convert the original
# CSV data into the se_open_data standard, one step at a time.
#
# We aim to put only logic specific to this project in this file, and
# keep it brief and clear. Shared logic should go into the {SeOpenData}
# library.
#
# This script can be invoked directly, or as part of the {SeOpenData}
# library's command-line API {SeOpenData::Cli}. For example, this
# just runs the conversion step (or specifically: a script in the
# current directory called `converter`):
#
#     seod convert 
#
# And this runs the complete chain of commands generating and
# deploying the linked data for this project, as configured by
# `settings/config.txt`:
#
#     seod run-all
#
# See the documentation on [`seod`]({SeOpenData::Cli}) for more
# information.

require 'se_open_data'
require 'se_open_data/config'
require 'se_open_data/csv/schema'
require 'se_open_data/csv/schema/types'
require 'se_open_data/csv/converter/limesurveycore'
require 'csv'


module Converter
  
  # The output schema
  StdSchema = SeOpenData::CSV::Schemas::Latest

  # A convenient alias...
  Types = SeOpenData::CSV::Schema::Types

  # Convert the exported JSON into CSV
  #
  # This is as simple as possible, the more complex things are done in
  # the conversion of this to standard.csv format.
  def self.convert_to_csv(headers:, input:, output:)
    input = File.read(input) unless input.is_a? IO
    output = output.is_a?(IO) ? CSV.new(output) : CSV.open(output, 'wb') 

    output << headers

    j_input = JSON.parse(input);
    j_input['records'].each do |record|
      fields = record['fields']
      output << headers.collect do |header|
        if header == 'id'
          record['id']
        else
          fields.fetch(header, nil)
        end
      end
    end
  ensure
    output.close
  end

  
  # Returns a schema converter for the given schema.
  #
  # This defines a schema mapping data into the standard schema.
  #
  # The logic that maps the input field data is defined in the
  # do-block. It will be wrapped in a loop which reads the input file
  # and writes the output file. See the documentation for
  # {SeOpenData::CSV::Schema.converter}.
  #
  def self.mk_converter(from_schema:, to_schema:)
    return SeOpenData::CSV::Schema.converter(
             from_schema: from_schema,
             to_schema: to_schema,
             input_csv_opts: {skip_blanks: true}
             #    output_csv_opts: {quote_empty: false}
           ) do
      | # These parameters match source schema field ids
        id:,
        name:,
        website:,
        street:,
        postcode:,
        latitude:,
        longitude:,
        description:,
        approved:
        |
        if approved&.downcase == 'true'
          raise "No name for item ##{id}" unless name
          {
            id: id,
            name: name,
            description: description,
            organisational_structure: nil,
            primary_activity: nil,
            activities: nil,
            street_address: street,
            locality: 'Oxford',
            region: nil,
            postcode: postcode,
            country_name: 'UK',
            #territory_id: nil,
            homepage: Types.normalise_url(website, default: nil),
            phone: nil,
            email: nil,
            twitter: nil,
            facebook: nil,
            companies_house_number: nil,
            qualifiers: nil,
            base_membership_type: nil,
            latitude: latitude,
            longitude: longitude,
            geocontainer: nil,
            geocontainer_lat: nil,
            geocontainer_lon: nil,
          };
        end
      end
  end
         
  # Entry point if invoked as a script.
  #
  # See {SeOpenData::Config} for information about this file. It
  # defines the locations of various resources, and sets options on
  # the conversion process.
  def self.main
    # Find the config file...
    config = SeOpenData::Config.load

    # This defines the input CSV schema we expect (after clean-up an index generation)
    schema = SeOpenData::CSV::Schema.load_file(config.ORIGINAL_CSV_SCHEMA)
    
    # original data file
    original_data = File.join(config.SRC_CSV_DIR, config.ORIGINAL_CSV)

    # Intermediate csv files
    converted_csv = File.join(config.GEN_CSV_DIR, "converted.csv")
    standard_csv = File.join(config.GEN_CSV_DIR, "standard.csv")

    # Output csv file
    output_csv = config.STANDARD_CSV

    # Convert the JSON data to csv.
    convert_to_csv(headers: schema.field_headers, input: original_data, output: converted_csv)
    
    # A converter between the input and standard csv schema
    converter = mk_converter(from_schema: schema, to_schema: StdSchema)

    # Convert the csv to the standard schema
    converter.convert File.open(converted_csv), standard_csv

    SeOpenData::CSV::Converter::LimeSurveyCore
      .add_postcode_lat_long(infile: standard_csv, outfile: output_csv,
                             lat_lng_cache: config.POSTCODE_LAT_LNG_CACHE,
                             to_schema: StdSchema)
  rescue => e
    raise "error transforming #{original_data} into #{output_csv}: #{e.message}"
  end

  private


end

# Run the entry point if we're invoked as a script
# This just does the csv conversion.
Converter.main if __FILE__ == $0


#!/usr/bin/env ruby
# coding: utf-8
#
# This script controls a pipeline of processes that convert the original
# CSV data into the se_open_data standard, one step at a time.
#
# We aim to put only logic specific to this project in this file, and
# keep it brief and clear. Shared logic should go into the {SeOpenData}
# library.
#
# This script can be invoked directly, or as part of the {SeOpenData}
# library's command-line API {SeOpenData::Cli}. For example, this
# just runs the conversion step (or specifically: a script in the
# current directory called `converter`):
#
#     seod convert 
#
# And this runs the complete chain of commands generating and
# deploying the linked data for this project, as configured by
# `settings/config.txt`:
#
#     seod run-all
#
# See the documentation on [`seod`]({SeOpenData::Cli}) for more
# information.

require 'se_open_data'
require 'se_open_data/config'
require 'se_open_data/csv/add_postcode_lat_long'
require 'se_open_data/csv/schema'
require 'se_open_data/csv/schema/types'
require 'csv'
require 'roo'


module Converter
  
  # The output schema
  StdSchema = SeOpenData::CSV::Schemas::Latest

  # A convenient alias...
  Types = SeOpenData::CSV::Schema::Types
    
  # Returns a schema converter for the given schema.
  #
  # This defines a schema mapping data into the standard schema.
  #
  # The logic that maps the input field data is defined in the
  # do-block. It will be wrapped in a loop which reads the input file
  # and writes the output file. See the documentation for
  # {SeOpenData::CSV::Schema.converter}.
  #
  # The response data downloaded from limesurvey via the API appears
  # to be different to that downloaded previously.
  # - semi-colon delimited, not comma delimited
  # - 'activities' field contains a identifier, not a human-readable phrase.
  #
  # The delimiter appears to be configurable in the web download, but not in the API.
  # https://bugs.limesurvey.org/view.php?id=13747
  def self.mk_converter(from_schema:, to_schema:)
    return SeOpenData::CSV::Schema.converter(
             from_schema: from_schema,
             to_schema: to_schema,
             input_csv_opts: {skip_blanks: true}
             #    output_csv_opts: {quote_empty: false}
           ) do
      | # These parameters match source schema field ids
        id:,
        name:,
        website:,
        facebook:,
        twitter:,
        location:,
        approved:,
        description:
        |
        # Inconveniently, the approved value gets converted as 1 or
        # true, depending on whether it came from OnlyOffice or
        # LibreOffice...
        if approved&.to_s == '1' || approved&.upcase == 'TRUE'
          # A mapping to the target schema field ids
          latlng = [nil, nil] # default
          if location
            latlng = location.to_s.split(';').collect {|it| Float(it) }
            raise "invalid location: '#{location}'" if latlng.size != 2 || latlng.include?(nil)
          end
          raise "No name for item ##{id}" unless name
          {
            id: id,
            name: name,
            description: description,
            organisational_structure: nil,
            primary_activity: nil,
            activities: nil,
            street_address: nil,
            locality: nil,
            region: nil,
            postcode: nil,
            country_id: nil,
            territory_id: nil,
            homepage: Types.normalise_url(website, default: nil),
            phone: nil,
            email: nil,
            twitter: Types.normalise_twitter([twitter, "http://twitter.com/#{twitter}", website], base_url: ''),
            facebook: Types.normalise_facebook([facebook, "http://fb.me/#{facebook}", website], base_url: ''),
            companies_house_number: nil,
            qualifiers: nil,
            base_membership_type: nil,
            latitude: latlng[0],
            longitude: latlng[1],
            geocontainer: nil,
            geocontainer_lat: nil,
            geocontainer_lon: nil,
          };
        end
      end
  end
         
  # Entry point if invoked as a script.
  #
  # See {SeOpenData::Config} for information about this file. It
  # defines the locations of various resources, and sets options on
  # the conversion process.
  def self.main
    # Find the config file...
    config = SeOpenData::Config.load

    # This defines the input CSV schema we expect (after clean-up an index generation)
    schema = SeOpenData::CSV::Schema.load_file(config.ORIGINAL_CSV_SCHEMA)
    
    # original src spreadsheet file
    original_spreadsheet = File.join(config.SRC_CSV_DIR, config.ORIGINAL_CSV)

    # Intermediate csv files
    converted_csv = File.join(config.GEN_CSV_DIR, "converted.csv")

    # Output csv file
    output_csv = config.STANDARD_CSV

    # Convert the spreadsheet to csv. Roo's API is a bit funky, and buggy:
    # to_csv does not work if there are boolean cells. See:
    # https://github.com/roo-rb/roo/issues/545
    sheet = Roo::Spreadsheet.open(original_spreadsheet).sheet(0)
    File.open(converted_csv, 'w') do |file|
      sheet.each.map do |row|
        file.puts row.to_csv
      end
    end
    
    # A converter between the input and standard csv schema
    converter = mk_converter(from_schema: schema, to_schema: StdSchema)

    # Convert the csv to the standard schema
    converter.convert File.open(converted_csv), output_csv
    
  rescue => e
    raise "error transforming #{original_csv} into #{output_csv}: #{e.message}"
  end

  private


end

# Run the entry point if we're invoked as a script
# This just does the csv conversion.
Converter.main if __FILE__ == $0

